{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451b5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import trange\n",
    "\n",
    "from bikebench.prediction.prediction_utils import TorchStandardScaler, Preprocessor\n",
    "from bikebench.prediction import aesthetics_predictor\n",
    "from bikebench.data_loading import data_loading\n",
    "from bikebench.resource_utils import models_and_scalers_path\n",
    "from bikebench.prediction.prediction_utils import TorchStandardScaler\n",
    "from bikebench.prediction.aesthetics_predictor import get_aesthetics_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b9e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tv, Y_tv = data_loading.load_aesthetics_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab30e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tv_tens = torch.tensor(X_tv.values, dtype=torch.float32, device=device)\n",
    "Y_tv_tens = torch.tensor(Y_tv, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51838256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tv_tens = aesthetics_predictor.remove_wall_thickness_and_material(X_tv_tens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537a3773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyler\\AppData\\Local\\Temp\\ipykernel_56516\\2807822398.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tv_tens = torch.tensor(scaler.transform(X_tv_tens), dtype=torch.float32, device=device)\n"
     ]
    }
   ],
   "source": [
    "scaler = TorchStandardScaler().to(device)\n",
    "scaler.fit(X_tv_tens)\n",
    "\n",
    "\n",
    "scaler_path = models_and_scalers_path(\"aesthetics_scaler.pt\")\n",
    "torch.save(scaler, scaler_path)\n",
    "\n",
    "X_tv_tens = torch.tensor(scaler.transform(X_tv_tens), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb2a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_tv_tens, Y_tv_tens, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50078baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [4:19:40<00:00, 77.90s/it, loss=0.0028, val_loss=0.0026, best_val=0.0026]  \n"
     ]
    }
   ],
   "source": [
    "model = get_aesthetics_model(dropout_on=True).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200 \n",
    "batch_size = 32\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "bar = trange(num_epochs, desc=\"Training\")\n",
    "for epoch in bar:\n",
    "    model.train()\n",
    "    permutation = torch.randperm(X_train.size(0))\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        indices = permutation[i : i + batch_size]\n",
    "        batch_x, batch_y = X_train[indices], Y_train[indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, Y_val)\n",
    "\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        best_model = model\n",
    "\n",
    "    bar.set_postfix({\n",
    "        'loss': f'{loss.item():.4f}',\n",
    "        'val_loss': f'{val_loss.item():.4f}',\n",
    "        'best_val': f'{best_val_loss:.4f}'\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = models_and_scalers_path(\"aesthetics_model_weights.pt\")\n",
    "# torch.save(best_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77130fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state  = torch.load(save_path, weights_only=True)\n",
    "\n",
    "model = get_aesthetics_model(dropout_on = False).to(device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9030cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted embedding more similar to GT than : 99.57% of test set designs, on average.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0060665542259812355"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluators\n",
    "\n",
    "evaluators.evaluate_aesthetics(model, Preprocessor(scaler_path=scaler_path, preprocess_fn=aesthetics_predictor.remove_wall_thickness_and_material, device=device), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dab8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike-bench-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
